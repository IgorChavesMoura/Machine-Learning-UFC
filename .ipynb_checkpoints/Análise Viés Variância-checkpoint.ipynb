{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import common as com\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de padrões: 846\n",
      "Número de atributos: 18\n",
      "Número de classes: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/anaconda3/lib/python3.7/site-packages/sklearn/datasets/openml.py:308: UserWarning: Multiple active versions of the dataset matching the name vehicle exist. Versions may be fundamentally different, returning version 1.\n",
      "  \" {version}.\".format(name=name, version=res[0]['version']))\n"
     ]
    }
   ],
   "source": [
    "#data = fetch_openml(name='mfeat-karhunen')\n",
    "#data = fetch_openml(name='heart-statlog')\n",
    "data = fetch_openml(name='vehicle')\n",
    "#data = fetch_openml(name='sonar')\n",
    "#data = fetch_openml(name='glass')\n",
    "#data = fetch_openml(name='ecoli')\n",
    "#data = fetch_openml(name='yeast')\n",
    "#data = fetch_openml(name='splice')\n",
    "#data = fetch_openml(name='vowel')\n",
    "#data = fetch_openml(name='credit-g')\n",
    "#data = fetch_openml(name='spambase')\n",
    "label_names = np.unique(data.target)\n",
    "x = data.data\n",
    "y = np.zeros(data.target.shape[0], dtype=int)\n",
    "for k, k_label in enumerate(label_names):\n",
    "    y[data.target == k_label] = k\n",
    "    \n",
    "train_ratio = 0.8\n",
    "validation_ratio = 0.2\n",
    "\n",
    "print(\"Número de padrões: %d\" % x.shape[0])\n",
    "print(\"Número de atributos: %d\" % x.shape[1])\n",
    "print(\"Número de classes: %d\" % np.unique(y).shape[0])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão Treino Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_train_test(x,y,normalize_data = True):\n",
    "    \n",
    "    number_train = int(np.ceil(train_ratio*(x.shape[0])))\n",
    "    random_index = np.random.permutation(x.shape[0])\n",
    "    train_index = random_index[:number_train+1]\n",
    "    test_index = random_index[number_train+1:]\n",
    "\n",
    "    x_train = x[train_index]\n",
    "    x_test = x[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "    \n",
    "    \n",
    "    if normalize_data:\n",
    "        x_mean = np.mean(x_train, axis=0)        \n",
    "        x_train -= x_mean\n",
    "        x_std = np.std(x_train, axis=0)\n",
    "        index_not_zero = x_std > 0\n",
    "        x_train[:,index_not_zero] /= x_std[index_not_zero]\n",
    "\n",
    "        x_test -= x_mean\n",
    "        x_test[:,index_not_zero] /= x_std[index_not_zero]\n",
    "    \n",
    "    #print(\"Número de padrões de treinamento: %d\" % len(y_train))\n",
    "    #print(\"Número de padrões de teste: %d\" % len(y_test))\n",
    "    \n",
    "    return x_train,x_test,y_train,y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise utilizando acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/igor/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/igor/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/igor/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/igor/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n",
      "/home/igor/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/igor/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "models_names = ['KNN', 'MLP', 'SVM', 'KNN-Bagging', 'MLP-Bagging']\n",
    "\n",
    "models_scores = {}\n",
    "\n",
    "for model_name in models_names:\n",
    "    \n",
    "    models_scores[model_name] = { 'train':[], 'test':[] }\n",
    "\n",
    "for i in range(50):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=20,activation='tanh',alpha=10**-2,batch_size=10)\n",
    "    svm = SVC(gamma='auto')\n",
    "    knn_bagging = BaggingClassifier(knn, n_estimators=10,\n",
    "                              max_samples=1.0, n_jobs=-1, random_state=12345)\n",
    "    mlp_bagging = BaggingClassifier(mlp, n_estimators=10,\n",
    "                              max_samples=1.0, n_jobs=-1, random_state=12345)\n",
    "    \n",
    "    models = [knn,mlp,svm,knn_bagging,mlp_bagging]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = div_train_test(x,y)\n",
    "    \n",
    "    for model,model_name in zip(models,models_names):\n",
    "        \n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        model_pred = model.predict(x_test)\n",
    "        \n",
    "        model_score_train = model.score(x_train,y_train)\n",
    "        \n",
    "        model_score_test = model.score(x_test,y_test)\n",
    "        \n",
    "        models_scores[model_name]['train'].append(model_score_train)\n",
    "        \n",
    "        models_scores[model_name]['test'].append(model_score_test)\n",
    "\n",
    "        \n",
    "        \n",
    "for model_name in models_names:\n",
    "    \n",
    "    train_mean = np.mean(models_scores[model_name]['train'])\n",
    "    test_mean = np.mean(models_scores[model_name]['test'])\n",
    "    \n",
    "    train_std = np.std(models_scores[model_name]['train'])\n",
    "    test_std = np.std(models_scores[model_name]['test'])\n",
    "    \n",
    "    print(\"[%s]: Média treino: %.2f%% - Média teste: %.2f%% - Desvio treino: %.2f%% - Desvio teste: %.2f%%\" % (model_name, train_mean,test_mean,train_std,test_std))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
